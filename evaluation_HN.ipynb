{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefad2c4",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20162ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.HN import *\n",
    "from utils.model_eval import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5afb7ae",
   "metadata": {},
   "source": [
    "### Define variables\n",
    "- `dets_file`: This is the path to the .csv file containing the HerdNet predictions. One row represents one detection as is expected to ahev the following columns:\n",
    "    - `images`: Contains the file names of the images.\n",
    "    - `x`: Contains the x-coordinate of the detection.\n",
    "    - `y`: Contains the y-coordinate of the detection.\n",
    "    - `scores`: Contains the confidence score of the prediction.\n",
    "    - `species`: Contains the name of the detected species.\n",
    "- `class_name2ID` is a dictionary mapping class names to their name. The ID of a species is its position in the Species column of Table 1. It's name is the name given in Table 1. E.g., for the JE-TL19 dataset, : `classID2name = {\"Elephant\": 0, \"Giraffe\": 1, \"Zebra\": 2}`\n",
    "- The DoR values can be found in Table 12.\n",
    "- The radii can be found in the Size Avg. column of Table 1. They need to be passed as a dictionary where `key = class ID`, `value = radius`. Again, for the JE-TL19 dataset, the `radii` dict would look as follows: `{0: 62, 1: 81, 2: 49}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf808c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dets_file = \"\"     #TODO: Insert path to the HerdNet output csv file.\n",
    "class_name2ID = {\"\": 0, \"\": 1, \"\": 2}    #TODO: Insert class names and IDs as found in Table 1.\n",
    "imgs_dir = \"\"   #TODO: Insert Path to image directory (as downloaded from Zenodo).\n",
    "dor_thresh = -1.0    #TODO: Define DoR threshold for NMS and computing evaluation metrics (cf. Table 12)\n",
    "radii = {0: None, 1: None, 2: None}     #TODO: Insert radius for each species in the dataset; cf. Table 1.\n",
    "output_dir = \"\"     #TODO: Insert path to directory you want your output stored in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eee3e2",
   "metadata": {},
   "source": [
    "### Read HerdNet output and run evaluation pipeline (no input required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_detections_HN(dets_file=dets_file, cls_name2id=class_name2ID, imgs_dir=imgs_dir, dor_thresh=dor_thresh, radii=radii, class_ids=list(radii.keys()), output_dir=output_dir,\n",
    "                   ann_file=f\"{imgs_dir}/test_annotations.json\", ann_format=\"PT_DEFAULT\")\n",
    "\n",
    "class_ID2name = {cid: name for name,cid in class_name2ID.values()}\n",
    "compute_errors_img_lvl(gt_counts_dir=f\"{imgs_dir}/image_counts\", pred_counts_dir=f\"{output_dir}/detections\", class_ids=list(class_ID2name.keys()), \n",
    "                           output_dir=output_dir)\n",
    "compute_em_img_lvl(preds_dir=f\"{output_dir}/detections\", class_id2name=class_ID2name, task=\"locate\", output_dir=output_dir)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P0_YOLOcate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
